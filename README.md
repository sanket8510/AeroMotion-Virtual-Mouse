# Hand Gesture-Controlled HCI Platform

This project introduces a **Hand Gesture-Controlled Human-Computer Interaction (HCI) Platform** using Python, MediaPipe, OpenCV, and Tkinter. The platform enhances accessibility and interaction by replacing traditional hardware inputs with intuitive hand gestures.

---

## 🚀 Features

✅ **Three Independent Modules:**
- **Virtual Mouse:** Control your mouse using hand gestures (move, click, drag, scroll).
- **Magic Canvas:** Digital drawing board that responds to gestures—draw, erase, change color.
- **Gesture Sync:** Control multimedia, browser navigation, system brightness, volume, and screenshots using gestures.

✅ **Real-Time Gesture Recognition:**  
Utilizes MediaPipe and OpenCV for accurate hand tracking and gesture detection.

✅ **Enhanced Accessibility & Sustainability:**  
Minimizes the need for physical input devices, enabling more inclusive and eco-friendly computing.

---

## 🖥️ Technologies Used
- **Python**  
- **MediaPipe**  
- **OpenCV**  
- **Tkinter (for GUI)**

---

## ⚙️ Installation & Setup

1. **Clone the Repository:**
```bash
git clone https://github.com/yourusername/gesture-hci-platform.git
cd gesture-hci-platform
```
Create a Virtual Environment (optional but recommended):

```bash
python -m venv venv
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate     # Windows
```

3.Install the Requirements:

```bash
Copy code
pip install -r requirements.txt
```

4. Run the command
   ```bash
   python gui.py

  ```
